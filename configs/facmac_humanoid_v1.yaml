# ================================================================
# FACMAC Configuration for MaMuJoCo Humanoid (Production v1)
# ================================================================
# This config matches NQMIX v1 for fair algorithm comparison
# Using Option 1 (Balanced) hyperparameters for optimal results

# Algorithm selection
algorithm: facmac

# ================================================================
# ENVIRONMENT SETTINGS
# ================================================================
env_name: Humanoid      # MuJoCo environment
partitioning: "9|8"     # Action split: agent_0 gets 9 dims, agent_1 gets 8 dims

# ================================================================
# TRAINING SETTINGS
# ================================================================
n_episodes: 60000       # Total training episodes (reduced from 100K with better hyperparams)
max_steps: 1000         # Max timesteps per episode
batch_size: 64          # Episodes sampled per training update
seed: 42                # Random seed for reproducibility

# ================================================================
# EVALUATION SETTINGS
# ================================================================
eval_freq: 100          # Evaluate every N episodes
n_eval_episodes: 10     # Episodes per evaluation (averaged for stability)
log_freq: 10            # Log training metrics every N episodes

# ================================================================
# EXPLORATION NOISE SETTINGS
# ================================================================
# Gaussian noise added to actions for exploration
# Decays exponentially from start to end over decay_episodes
noise_scale_start: 0.12   # Initial noise std (high exploration)
noise_scale_end: 0.02     # Final noise std (low exploration)
noise_decay_episodes: 1500 # Episodes to decay from start to end

# ================================================================
# AGENT HYPERPARAMETERS
# ================================================================
agent_params:
  # Network architecture
  hidden_dim: 128         # GRU hidden state size

  # Learning rates (balanced - 6x higher than original v1)
  lr_actor: 0.0003        # Actor network learning rate
  lr_critic: 0.0003       # Critic network learning rate

  # RL hyperparameters
  gamma: 0.99             # Discount factor for future rewards
  tau: 0.005              # Soft target update rate (increased from 0.001 for faster convergence)

  # Replay buffer
  buffer_capacity: 50000  # Max episodes stored (large buffer for stability)

  # Action bounds (must match environment)
  action_low: -0.4        # Minimum action value for Humanoid
  action_high: 0.4        # Maximum action value for Humanoid

# ================================================================
# OUTPUT SETTINGS
# ================================================================
save_dir: ./results/facmac_humanoid_v1  # Where to save logs, models, TensorBoard
